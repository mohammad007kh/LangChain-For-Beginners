{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0019e2",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# بخش ۸: اجرای موازی ایجنت‌ها در LangChain\n",
    "\n",
    "در این بخش یاد می‌گیریم چطور چندین ایجنت یا وظیفه را به‌صورت موازی اجرا کنیم تا زمان پاسخ‌دهی را کاهش دهیم و کارایی سیستم را افزایش دهیم.\n",
    "\n",
    "## اهداف یادگیری\n",
    "- آشنایی با مفهوم اجرای موازی (Parallel Execution) در LangChain\n",
    "- یادگیری استفاده از RunnableParallel برای اجرای همزمان چند تسک\n",
    "- مقایسه زمان اجرای سریالی و موازی\n",
    "- ساخت یک مثال عملی با چند ایجنت موازی\n",
    "\n",
    "## فهرست مطالب\n",
    "1. مقدمه و مفهوم اجرای موازی\n",
    "2. نصب کتابخانه‌ها و تنظیمات اولیه\n",
    "3. مثال ساده: اجرای موازی با RunnableParallel\n",
    "4. مقایسه زمان اجرای سریالی و موازی\n",
    "5. مثال پیشرفته: ایجنت‌های موازی با ابزارهای مختلف\n",
    "6. تمرین و جمع‌بندی\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aeee98",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۱. مقدمه و مفهوم اجرای موازی\n",
    "\n",
    "**چرا اجرای موازی؟**  \n",
    "زمانی که می‌خواهیم چند وظیفه مستقل را انجام دهیم (مثلاً پرسیدن چند سؤال مختلف از مدل)، اگر به‌صورت سریالی اجرا کنیم، زمان زیادی صرف می‌شود. با اجرای موازی می‌توانیم این وظایف را همزمان انجام دهیم و زمان کل را کاهش دهیم.\n",
    "\n",
    "**مزایا:**\n",
    "- کاهش زمان پاسخ‌دهی\n",
    "- افزایش کارایی سیستم\n",
    "- امکان مدیریت چند درخواست همزمان\n",
    "\n",
    "**کاربردها:**\n",
    "- پردازش همزمان چند سؤال\n",
    "- تحلیل چند سند به‌صورت موازی\n",
    "- اجرای ایجنت‌های مستقل با ابزارهای مختلف\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03c0e9",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۲. نصب کتابخانه‌ها و تنظیمات اولیه\n",
    "\n",
    "**کتابخانه‌های مورد نیاز:**\n",
    "```bash\n",
    "pip install langchain langchain-openai langchain-groq python-dotenv\n",
    "```\n",
    "\n",
    "در این بخش، مدل OpenAI را برای تست‌های موازی راه‌اندازی می‌کنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892d2c7",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۳. مثال ساده: اجرای موازی با RunnableParallel\n",
    "\n",
    "**RunnableParallel چیست؟**  \n",
    "این ابزار به ما اجازه می‌دهد چند زنجیره یا وظیفه را به‌صورت موازی اجرا کنیم. هر کدام از وظایف می‌تواند یک پرامپت جداگانه یا یک chain مستقل باشد.\n",
    "\n",
    "**مثال:**  \n",
    "ما سه سؤال مختلف می‌پرسیم و همه را به‌صورت موازی اجرا می‌کنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa56299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define three different prompts\n",
    "prompt1 = PromptTemplate(input_variables=[\"topic\"], template=\"What is {topic}?\")\n",
    "prompt2 = PromptTemplate(input_variables=[\"topic\"], template=\"Give me 3 benefits of {topic}.\")\n",
    "prompt3 = PromptTemplate(input_variables=[\"topic\"], template=\"What are common challenges with {topic}?\")\n",
    "\n",
    "# Create three chains\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "chain3 = prompt3 | llm | StrOutputParser()\n",
    "\n",
    "# Run them in parallel\n",
    "parallel_chain = RunnableParallel(\n",
    "    definition=chain1,\n",
    "    benefits=chain2,\n",
    "    challenges=chain3\n",
    ")\n",
    "\n",
    "result = parallel_chain.invoke({\"topic\": \"machine learning\"})\n",
    "\n",
    "print(\"Definition:\", result[\"definition\"])\n",
    "print(\"\\nBenefits:\", result[\"benefits\"])\n",
    "print(\"\\nChallenges:\", result[\"challenges\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4228d",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "**توضیح کد:**\n",
    "1. سه پرامپت مختلف تعریف کردیم که هر کدام سؤال متفاوتی می‌پرسند\n",
    "2. هر پرامپت را به LLM و یک output parser متصل کردیم\n",
    "3. با استفاده از `RunnableParallel`، هر سه زنجیره را به‌صورت موازی اجرا می‌کنیم\n",
    "4. نتایج را به‌صورت یک دیکشنری دریافت می‌کنیم\n",
    "\n",
    "**نکته:** اجرای موازی زمان کل را نسبت به اجرای سریالی کاهش می‌دهد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053ddb4",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۴. مقایسه زمان اجرای سریالی و موازی\n",
    "\n",
    "حالا همان سه سؤال را یک‌بار به‌صورت سریالی و یک‌بار به‌صورت موازی اجرا می‌کنیم و زمان آن‌ها را مقایسه می‌کنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial execution\n",
    "start_serial = time.time()\n",
    "r1 = chain1.invoke({\"topic\": \"Python programming\"})\n",
    "r2 = chain2.invoke({\"topic\": \"Python programming\"})\n",
    "r3 = chain3.invoke({\"topic\": \"Python programming\"})\n",
    "end_serial = time.time()\n",
    "\n",
    "serial_time = end_serial - start_serial\n",
    "print(f\"Serial execution time: {serial_time:.2f} seconds\")\n",
    "\n",
    "# Parallel execution\n",
    "start_parallel = time.time()\n",
    "results_parallel = parallel_chain.invoke({\"topic\": \"Python programming\"})\n",
    "end_parallel = time.time()\n",
    "\n",
    "parallel_time = end_parallel - start_parallel\n",
    "print(f\"Parallel execution time: {parallel_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nSpeedup: {serial_time / parallel_time:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda9b6a",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "**نتیجه:**  \n",
    "همان‌طور که می‌بینید، اجرای موازی معمولاً ۲ تا ۳ برابر سریع‌تر از اجرای سریالی است، چون درخواست‌ها همزمان ارسال می‌شوند.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69192b9d",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۵. مثال پیشرفته: استفاده از ایجنت‌ها با ابزارهای مختلف به‌صورت موازی\n",
    "\n",
    "در این بخش، یک ایجنت می‌سازیم که چند ابزار دارد و می‌تواند چند سؤال را همزمان پردازش کند.\n",
    "\n",
    "**سناریو:**  \n",
    "ما می‌خواهیم:\n",
    "1. یک محاسبه ریاضی انجام دهیم\n",
    "2. اطلاعات یک شهر را پیدا کنیم\n",
    "3. یک توضیح کوتاه درباره یک موضوع بگیریم\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c776667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression and return the result.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"The result is: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_city_info(city: str) -> str:\n",
    "    \"\"\"Get basic information about a city.\"\"\"\n",
    "    # Mock data for demonstration\n",
    "    cities = {\n",
    "        \"Tehran\": \"Capital of Iran, population ~9 million\",\n",
    "        \"Paris\": \"Capital of France, known for Eiffel Tower\",\n",
    "        \"Tokyo\": \"Capital of Japan, largest metropolitan area\"\n",
    "    }\n",
    "    return cities.get(city, f\"No information available for {city}\")\n",
    "\n",
    "@tool\n",
    "def explain_concept(concept: str) -> str:\n",
    "    \"\"\"Provide a brief explanation of a concept.\"\"\"\n",
    "    return f\"Explaining {concept}: This is a placeholder explanation for demonstration purposes.\"\n",
    "\n",
    "tools = [calculate, get_city_info, explain_concept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create agent\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools to answer questions.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agent with a single query first\n",
    "test_result = agent_executor.invoke({\"input\": \"Calculate 234 * 567\"})\n",
    "print(\"Test Result:\", test_result[\"output\"])\n",
    "\n",
    "# Now run multiple queries in parallel\n",
    "query1 = \"Calculate 234 * 567\"\n",
    "query2 = \"Tell me about Tehran\"\n",
    "query3 = \"Explain quantum computing\"\n",
    "\n",
    "# Using RunnableParallel with agent\n",
    "# Note: Each lambda needs to accept an input parameter even if not used\n",
    "parallel_agent_chain = RunnableParallel(\n",
    "    calculation=lambda _: agent_executor.invoke({\"input\": query1}),\n",
    "    city_info=lambda _: agent_executor.invoke({\"input\": query2}),\n",
    "    concept=lambda _: agent_executor.invoke({\"input\": query3})\n",
    ")\n",
    "\n",
    "results = parallel_agent_chain.invoke({})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Calculation Result:\", results[\"calculation\"][\"output\"])\n",
    "print(\"\\nCity Info:\", results[\"city_info\"][\"output\"])\n",
    "print(\"\\nConcept Explanation:\", results[\"concept\"][\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a981c",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "**توضیح:**  \n",
    "- سه ابزار مختلف ساختیم: محاسبه‌گر، اطلاعات شهر، و توضیح‌دهنده مفهوم\n",
    "- یک ایجنت با این ابزارها ساختیم\n",
    "- سه سؤال مختلف را به‌صورت موازی اجرا کردیم\n",
    "- هر کدام از این سؤال‌ها می‌تواند از ابزار مناسب خود استفاده کند\n",
    "\n",
    "**مزیت:** در یک سیستم واقعی، این روش می‌تواند زمان پاسخ‌دهی را به‌طور قابل‌توجهی کاهش دهد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83155738",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "**نکات مهم درباره نسخه جدید LangChain:**\n",
    "\n",
    "1. **تغییر import ابزارها:** در نسخه‌های جدید، `@tool` از `langchain_core.tools` import می‌شود نه `langchain.agents`\n",
    "2. **lambda functions:** هنگام استفاده از `RunnableParallel` با agent executor، باید lambda ها یک پارامتر بگیرند (حتی اگر استفاده نشود)\n",
    "3. **سازگاری:** کد بالا با LangChain 0.3.x و بالاتر سازگار است\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72996df",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "---\n",
    "\n",
    "### ۶. تمرین و جمع‌بندی\n",
    "\n",
    "**تمرین‌های پیشنهادی:**\n",
    "\n",
    "1. **تمرین ساده:** یک `RunnableParallel` بسازید که سه سؤال مختلف درباره یک زبان برنامه‌نویسی بپرسد (تاریخچه، مزایا، کاربردها).\n",
    "\n",
    "2. **تمرین متوسط:** مقایسه زمان اجرا را برای ۵ سؤال مختلف انجام دهید و ببینید چقدر سرعت افزایش می‌یابد.\n",
    "\n",
    "3. **تمرین پیشرفته:** یک سیستم بسازید که اطلاعات چند شهر را به‌صورت موازی دریافت کند و مقایسه کند.\n",
    "\n",
    "4. **چالش:** ایجنتی بسازید که بتواند چند درخواست API را به‌صورت موازی اجرا کند و نتایج را ترکیب کند.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025281b",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "**جمع‌بندی نکات کلیدی:**\n",
    "\n",
    "1. **RunnableParallel** ابزاری قدرتمند برای اجرای همزمان چند وظیفه است\n",
    "2. اجرای موازی می‌تواند زمان پاسخ را ۲ تا ۳ برابر کاهش دهد\n",
    "3. برای سیستم‌هایی که باید چند درخواست مستقل را پردازش کنند، این روش بسیار مفید است\n",
    "4. می‌توان از این روش هم برای زنجیره‌های ساده و هم برای ایجنت‌ها استفاده کرد\n",
    "5. در محیط‌های production، حتماً محدودیت‌های API rate limit را در نظر بگیرید\n",
    "\n",
    "**منابع بیشتر:**\n",
    "- [LangChain LCEL Documentation](https://python.langchain.com/docs/expression_language/)\n",
    "- [RunnableParallel Guide](https://python.langchain.com/docs/expression_language/primitives/parallel)\n",
    "- [Agent Documentation](https://python.langchain.com/docs/modules/agents/)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
