{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "#VSC-b2209700",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "# شروع کار با LangChain و Ollama\n",
        "#### در این بخش، با نحوه استفاده از Ollama برای اجرای مدل‌های زبانی بزرگ (LLM) به صورت کاملاً محلی آشنا می‌شویم. با Ollama می‌توانید مدل‌ها را بدون نیاز به سرویس‌های ابری یا کلید API اجرا کنید و به راحتی با LangChain ادغام نمایید.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-03ef26d0",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "### نصب و بارگذاری مدل با Ollama\n",
        "برای استفاده از Ollama، ابتدا باید برنامه را نصب کنید و مدل مورد نظر را با دستور ساده دریافت نمایید. سپس می‌توانید مدل را با LangChain فراخوانی کنید.\n",
        "\n",
        "۱. نصب Ollama از سایت [ollama.com](https://ollama.com/download)\n",
        "۲. دریافت مدل (مثلاً mistral):\n",
        "\n",
        "```bash\n",
        "ollama serve\n",
        "```\n",
        "\n",
        "```bash\n",
        "ollama pull mistral\n",
        "```\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-96c306c9",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "### ساخت مدل زبانی محلی با Ollama و LangChain\n",
        "در این سلول، مدل را با LangChain و Ollama مقداردهی می‌کنیم و آماده استفاده می‌سازیم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a113361f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1. SmartLife\n",
            "\n",
            "2. EcoSphere\n",
            "\n",
            "3. InnovateX\n",
            "\n",
            "4. QuantumGear\n",
            "\n",
            "5. PureTech\n",
            "\n",
            "6. FutureFusion\n",
            "\n",
            "7. TechNova\n",
            "\n",
            "8. GeniusLink\n",
            "\n",
            "9. AvantEdge\n",
            "\n",
            "10. IdeaWave\n",
            "\n",
            "11. BrainBoost\n",
            "\n",
            "12. IntelliSpace\n",
            "\n",
            "13. NextGenX\n",
            "\n",
            "14. LuminaTech\n",
            "\n",
            "15. NeuralNet\n",
            "\n",
            "16. DynamicDrive\n",
            "\n",
            "17. QuantumQuartz\n",
            "\n",
            "18. AstraTech\n",
            "\n",
            "19. MegaMind\n",
            "\n",
            "20. ZenithInnovate\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "llm = Ollama(model=\"mistral\")  # or \"llama2\", \"llama3\", etc.\n",
        "response = llm.invoke(\"لیست ۱۰ نام خلاقانه برای یک محصول جدید بنویس. هر نام را در یک خط جداگانه بنویس.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "#VSC-282dc53f",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1. EchoFone', '2. ZippyLoop', '3. FluxoFlow', '4. PixeloPix', '5. SoniSphere', '6. BioMorphic', '7. QuantumQuill', '8. WaveWright', '9. NexusNook', '10. SwiftSpark', '11. VortexVibe', '12. PentaPulse', '13. SynthStream', '14. TerraTrend', '15. LuminoLabs', '16. QuantumQuill Pro', '17. EchoEssence', '18. SwiftSpark X', '19. ZippyLoop Plus', '20. FluxoFlow Fusion']\n"
          ]
        }
      ],
      "source": [
        "# Use Ollama locally with LangChain\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "# Create the LLM object for the desired model (e.g., mistral)\n",
        "llm = Ollama(model=\"mistral\")  # You can use \"llama2\", \"phi\", etc.\n",
        "\n",
        "# Generate a list of product names using the local Ollama model\n",
        "response = llm.invoke(\"لیست ۱۰ نام خلاقانه برای یک محصول جدید بنویس. هر نام را در یک خط جداگانه بنویس.\")\n",
        "name_list = [line.strip() for line in response.split(\"\\n\") if line.strip()]\n",
        "print(name_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-b4568b3f",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "### آشنایی با PromptTemplate\n",
        "در این سلول، با مفهوم قالب‌های پرامپت (PromptTemplate) آشنا می‌شویم و یک نمونه ساده با مدل Ollama می‌سازیم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "#VSC-625e935e",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a short message in English and in a friendly tone: Welcome to LangChain!\n"
          ]
        }
      ],
      "source": [
        "# Create a prompt template for structured input\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Write a short message in {language} and in a {tone} tone: {message}\",\n",
        "    input_variables=[\"tone\", \"message\", \"language\"],\n",
        ")\n",
        "\n",
        "filled_prompt = prompt.format(tone=\"friendly\", language=\"English\", message=\"Welcome to LangChain!\")\n",
        "print(filled_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-3bba274c",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "#### استفاده از قالب پرامپت برای تولید پیام با مدل Ollama\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "#VSC-13b6498d",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hello there!\n",
            "\n",
            "Welcome to LangChain! We're thrilled to have you with us. This community is all about the exciting world of language technology, where we can learn, share, and grow together. Whether you're a seasoned professional or just starting out, we welcome your contributions and look forward to your active participation.\n",
            "\n",
            "Let's embark on this incredible journey of language innovation together! If you have any questions or need assistance, feel free to ask. We're here to help!\n",
            "\n",
            "Best wishes,\n",
            "The LangChain Team\n"
          ]
        }
      ],
      "source": [
        "# Use the filled prompt with the local Ollama model\n",
        "response = llm.invoke(filled_prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "#VSC-19c5ee8c",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello there!\n",
            "\n",
            "Welcome to LangChain! We're thrilled to have you with us. This community is all about the exciting world of language technology, where we can learn, share, and grow together. Whether you're a seasoned professional or just starting out, we welcome your contributions and look forward to your active participation.\n",
            "\n",
            "Let's embark on this incredible journey of language innovation together! If you have any questions or need assistance, feel free to ask. We're here to help!\n",
            "\n",
            "Best wishes,\n",
            "The LangChain Team\n"
          ]
        }
      ],
      "source": [
        "# Print each line of the response\n",
        "lines = response.split('\\n')\n",
        "for line in lines:\n",
        "    print(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "#VSC-17aed8a1",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a short message in English and in a friendly tone: Welcome to Python Course!\n",
            " Hello there!\n",
            "\n",
            "Welcome aboard the Python Course! 🚀 We're thrilled to have you join us on this exciting journey. Get ready to embark on an adventure where you'll learn about programming, problem-solving, and creating amazing things with Python. Whether you're a beginner or a seasoned coder, we've got something for everyone. Let's dive in and make the most of it! 🤗\n",
            "\n",
            "Best of luck on your journey with us, and remember - have fun while learning! 🎉 #PythonLearningAdventure\n"
          ]
        }
      ],
      "source": [
        "# Try another prompt\n",
        "filled_prompt = prompt.format(tone=\"friendly\", language=\"English\", message=\"Welcome to Python Course!\")\n",
        "print(filled_prompt)\n",
        "response = llm.invoke(filled_prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-a5208888",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "## گرفتن خروجی مدل Ollama با استفاده از قالب پرامپت\n",
        "در این سلول، پیام ساخته‌شده را به مدل Ollama می‌دهیم و خروجی مدل را مشاهده می‌کنیم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "#VSC-3b5a8bb1",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title:  Title 1: \"Mastering LangChain: A Beginner's Guide to Getting Started!\"\n",
            "\n",
            "Title 2: \"LangChain for Newbies: Your Friendly Introduction to Translation Magic!\"\n",
            "\n",
            "Title 3: \"Unlock Language Barriers with LangChain! A Step-by-Step Tutorial for Beginners.\"\n",
            "\n",
            "Title 4: \"Beginner's Delight: Discover LangChain - The Easy Way to Translate!\"\n",
            "\n",
            "Title 5: \"Language Learning Made Easy with LangChain! Your First Steps Explored.\"\n",
            "Description:  Title: \"Get Started with LangChain: A Friendly Guide for Beginners!\"\n",
            "\n",
            "Welcome to our exciting journey into the realm of LangChain! This tutorial is tailored just for you, whether you're a language lover or new to digital language learning. Our goal is to help you navigate LangChain with ease and confidence, turning you into a pro in no time! So, let's embark on this adventure together, uncovering new horizons of digital language mastery! 🌐🚀📚\n",
            "\n",
            "Here's what we'll cover:\n",
            "\n",
            "1. **Introduction to LangChain:** We'll introduce you to LangChain, its purpose, and the benefits it offers for language learners like you.\n",
            "\n",
            "2. **Setting Up Your Account:** Step-by-step instructions on how to create your LangChain account and get ready to dive into the world of digital languages.\n",
            "\n",
            "3. **Navigating the Interface:** We'll familiarize you with LangChain's user-friendly interface, making sure you feel comfortable as we explore together.\n",
            "\n",
            "4. **Starting Your Language Learning Journey:** Discover how to select your preferred language and begin your learning adventure.\n",
            "\n",
            "5. **Exploring Features:** From interactive lessons to vocabulary quizzes, we'll show you how to make the most of LangChain's features for effective learning.\n",
            "\n",
            "6. **Tracking Progress:** Learn how to monitor your progress and celebrate your achievements along the way!\n",
            "\n",
            "7. **Tips & Tricks:** We'll share some handy tips to help you maximize your learning experience on LangChain.\n",
            "\n",
            "By the end of this tutorial, you'll be well-equipped to harness the power of LangChain for your language learning needs. So, are you ready to unlock new possibilities? Let's get started! 🚀📚\n"
          ]
        }
      ],
      "source": [
        "# Chain example: generate title and description using Ollama\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Title prompt template\n",
        "prompt_title = PromptTemplate(\n",
        "    template=\"Generate a catchy tutorial title in {language} and in a {tone} tone for: {message}\",\n",
        "    input_variables=[\"tone\", \"message\", \"language\"],\n",
        ")\n",
        "\n",
        "# Description prompt template\n",
        "prompt_desc = PromptTemplate(\n",
        "    template=\"Write a short description for a tutorial titled '{title}' in {language} and in a {tone} tone. The topic is: {message}\",\n",
        "    input_variables=[\"tone\", \"message\", \"language\", \"title\"],\n",
        ")\n",
        "\n",
        "# Output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Title chain\n",
        "title_chain = prompt_title | llm | output_parser\n",
        "\n",
        "# Description chain (takes the output of title_chain)\n",
        "desc_chain = (\n",
        "    RunnablePassthrough.assign(title=title_chain)\n",
        "    | prompt_desc\n",
        "    | llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "# Example inputs\n",
        "inputs = {\"tone\": \"friendly\", \"language\": \"English\", \"message\": \"How to use LangChain for beginners\"}\n",
        "\n",
        "title = title_chain.invoke(inputs)\n",
        "description = desc_chain.invoke(inputs)\n",
        "\n",
        "print(\"Title:\", title)\n",
        "print(\"Description:\", description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-9a75f355",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "## پیاده‌سازی زنجیره تولید عنوان و توضیح آموزش با مدل Ollama\n",
        "در این سلول، دو زنجیره ساده برای تولید عنوان و توضیح آموزش با مدل Ollama پیاده‌سازی می‌کنیم و نتیجه را نمایش می‌دهیم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "#VSC-ea94ec96",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title:  \"به روز رسانی فردی با LangChain: چگونه می‌توانم شروع کنم؟\"\n",
            "\n",
            "This title translates to \"Personalized Update with LangChain: How can I get started?\" and is designed to be friendly, approachable, and engaging for beginners in Persian. It uses the phrase \"به روز رسانی فردی\" (personalized update) which is commonly used in Persian tech content to indicate tutorials or guides specifically tailored to individual users. The use of \"چگونه می‌توانم شروع کنم?\" (How can I get started?) at the end emphasizes the tutorial's focus on beginners and encourages them to take action.\n",
            "Description:  درس آموزشی ساده: محلی کننده LangChain - برای شروع کنندگان! در این درس آموزشی، به تعرفه خود یافته‌ایم که LangChain چیست و چطور می توان به آن استفاده کنیم. حالات مجاز و ممنوع کاربرد LangChain را می خواهیم که از طریق آن، شما را به استفاده از حالات ممنوع و مجاز به صورت پایه‌ای آشنا می کند. این درس آموزشی به شروع کنندگان، طرح جدید و چیزهای جدیدی را معرفی می کند که در LangChain قابل استفاده می‌شوند. گروه محترم، از طریق پروژه های آنلاین و درخواست های عملی، به شما کمک می کند تا LangChain را به صورت خودکار استفاده کنید!\n"
          ]
        }
      ],
      "source": [
        "# Chain example with Persian input\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Title prompt template\n",
        "prompt_title = PromptTemplate(\n",
        "    template=\"Generate a catchy tutorial title in {language} and in a {tone} tone for: {message}\",\n",
        "    input_variables=[\"tone\", \"message\", \"language\"],\n",
        ")\n",
        "\n",
        "# Description prompt template\n",
        "prompt_desc = PromptTemplate(\n",
        "    template=\"Write a short description for a tutorial titled '{title}' in {language} and in a {tone} tone. The topic is: {message}\",\n",
        "    input_variables=[\"tone\", \"message\", \"language\", \"title\"],\n",
        ")\n",
        "\n",
        "# Output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Title chain\n",
        "title_chain = prompt_title | llm | output_parser\n",
        "\n",
        "# Description chain (takes the output of title_chain)\n",
        "desc_chain = (\n",
        "    RunnablePassthrough.assign(title=title_chain)\n",
        "    | prompt_desc\n",
        "    | llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "# Example inputs\n",
        "inputs = {\"tone\": \"friendly\", \"language\": \"Persian\", \"message\": \"How to use LangChain for beginners\"}\n",
        "\n",
        "title = title_chain.invoke(inputs)\n",
        "description = desc_chain.invoke(inputs)\n",
        "\n",
        "print(\"Title:\", title)\n",
        "print(\"Description:\", description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "#VSC-a656082b",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "الان می‌تونید با تغییر «tone»، «language» یا «message» در دیکشنری «inputs» آزمایش کنید تا ببینید عنوان و توضیحات چجوری تغییر می‌کنند. این نشون میده که چجوری زنجیره‌ها به ما امکان می‌دهند گردش‌های کاری پیچیده‌تر و ماژولارتری را در LangChain با مدل Ollama بسازیم.\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
